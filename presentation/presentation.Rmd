---
header-includes: \usepackage{booktabs}
title: "Modélisation de la probabilité de résignation"
author: "Charles Comeau, Nicholas Langevin et Andréanne Larouche"
date: "22/04/2020"
output: 
        ioslides_presentation:
            widescreen: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
load("../data/trainData.RData")
load("../data/testData.RData")
data <- rbind(trainData, testData)
library(ggplot2)
library(knitr)
library(kableExtra)
library(CASdatasets)
library(xtable)
library(glmnet)
<<<<<<< HEAD
library(scales)
library(gridExtra)
=======
library(gbm)
>>>>>>> 10f6790... Presentation parties 6 et 7
source("../script/_utilityFunction.R")
data(eudirectlapse)
data.init <- eudirectlapse

## Necessaire pour traitement données
data.init[data.init$polholder_diffdriver == "unknown", ]$polholder_diffdriver <- NA
data.init[data.init$vehicl_garage == "unknown", ]$vehicl_garage <- NA
data.init[data.init$policy_caruse == "unknown", ]$policy_caruse <- NA

## Import pour Lasso
load(file="../src/02-lasso/lasso.valid.dev.rds")
load(file="../src/02-lasso/lasso.valid.auc.rds")

## Import pour gbm 
load(file = "../src/07-gbm/gbm_opti_ROC.rds")
```

```{R, FonctionPrintTable, echo = FALSE, include = FALSE, warning = FALSE}
print.tables <- function(dat, caption="", label="", align=rep("c", ncol(dat)+1), digits=3, ...){
  print(xtable(dat, digits = digits,
             caption=caption,
             label=label,
             align=align,),
            include.rownames = FALSE, sanitize.text.function=function(x){x},
            caption.placement = "top", comment=FALSE, type = "html")
}
```

<!-- Introduction

-->

## Plan de la présentation

- Description du problème dans un context actuariel
- Exploration des données utilisées
- Prétraitement des données et exploration non-supevisée
- Description des modèles considérés
- Performance et interprétation des meilleurs modèles
- Conclusion

## Description du problème dans un context actuariel
<!-- 
Dans un context d'assurance, il est important de savoir si un assurer à 
beaucoup de chance de renouveler sont contrat pour l'année suivant. Pourquoi?

- Taux de rétention;
  Savoir combien de personnes vont renouveler permet de faire un estimation
  du taux de rétention. Le taux de rétention est important dans la compagnie 
  pour deux raison. 1. Permet de calculé le taux de croissance. 
  Renouvellement + nouvelles police > 100% indique que la compagnie est
  croissante en terme d'unité. 2. Indicateur de la compétitive dans le marché.
  Si le taux de rétention réelle est plus petit que celui prédit, une raison
  potentielle est que les compétiteurs offrent des meilleurs prix, ou encore
  que le service à la clientèle porte des lacunes.
  
- Élasticité:
  Une autre raison de calculé la probabilité de renouvellement est pour calculé
  l'élastique. Ceci représente la variation dans la probabilité de
  renouvellement pour un variation de prix donnée. Ceci permet de déterminer de
  combien l'augmentation de la prime sera pour chaque contrat. Plus la
  prédiction de renouvellement pour une police donnée est grande, plus
  l'assureur en profitera pour augmenter la prime.
-->
- Taux de rétention:
  $$
    \text{Taux de rétention} = \frac{\text{# Renouvellement}}{\text{# Police
    total}}
  $$
<!--    - Taux de croissance
    - Indicateur de compétitive
-->
- Élasticité:
  $$
    \text{Élasticité} = \frac{\Delta Pr[\text{Renouvellement}]}{\Delta
    \text{Augmentation prix}}
  $$
  

## Descriptions du jeu de données
<!-- 
Notre jeu de données représente le statut de renouvellement pour 23 060 
polices basées sur un an d'observation. 
-->
```{r}
nbRenou <- sum(data$lapse == levels(data$lapse)[1]) / nrow(data)
nbResign <- sum(data$lapse == levels(data$lapse)[2]) / nrow(data)
```

- `r nrow(data)` observations
- 8 variables numériques
- 8 variables catégoriels 
- 2 variables ordonnées
- 1 Variable crée:
  $$
    \text{prem_index} = \frac{\text{prem_final}}{\text{prem_last}}
  $$
- 1 Variable réponse:
    - `r round(nbRenou, 2)*100` % Renouvellement 
    - `r round(nbResign, 2)*100` % Résignation

## Analyse exploratoire (prime)
<!--
Graphique du % d'augmentation de la prime en fonction du status de rouvellement. On voit bien que l'augmentation de la prime est influencer par le classement bonus-malus de l'assurer. Le système bonus malus est utilisé en assurance pour déterminer le risque de l'assurer. par exemple, lorsque celui-ci fait un accident, il sera monter d'une cathégorie et donc d'un catégorie de prime. Bonus malus est comme
un resumer de la frequence et severiter.

On voit que seut qui augmente on effectivement un hausse de prime, les stable status-co et une diminution entraine aussi un diminution de la prime. 

De plus, dans le cas d'une augmentation de bonus malus, le 3e quartil semble legerement plus elever.
-->
```{r}
ggplot(data, aes(x=lapse, y=prem_index, col=polholder_BMCevol)) + geom_boxplot() +
    # facet_grid(col=vars(polholder_BMCevol)) + 
    ylab("Augmentation de la prime") + 
    xlab("") + 
    ggtitle("Augmentation de la prime en fonction du status de Renouvellement") +
    scale_y_continuous(labels = percent) + 
    scale_colour_discrete(name = "Système\nBonus Malus") +
    theme_bw()

# ggplot(data, aes(x=lapse, y=prem_final/prem_pure, col=polholder_BMCevol)) + geom_boxplot() +
#     # facet_grid(col=vars(polholder_BMCevol)) + 
#     ylab("Augmentation de la prime") + 
#     xlab("") + 
#     ggtitle("Augmentation de la prime en fonction du status de Renouvellement") +
#     scale_y_continuous(labels = percent) + 
#     scale_colour_discrete(name = "Système\nBonus Malus") +
#     theme_bw()
```


## Prétraitement des données

### Traitement des valeurs manquantes

<br/>

- policy_caruse: 3483

- vehicl_garage: 1575

- polholder_diffdriver: 12

- Nombre d'observations touchées: `r nrow(data) - nrow(na.omit(data.init))` (`r round((nrow(data) - nrow(na.omit(data.init))) / nrow(data) *100, 2)`%)

- Les données ne sont pas MCAR

- Imputation multiple



## Prétraitement des données

### Modification de vehicl_powerkw

![](tab_powerkw.PNG)

# Description des modèles

## Modèle de base

- GLM Bernoulli

- Modélisation de la probabilité de résignation avec régression logistique

<font size = "4">
$$\ln \frac{\pi_{res}}{1 - \pi_{res}} = \beta_0 + \sum_{i=1}^p \beta_i x_i$$
</font>
- Estimateurs $\beta_{i}$ 
<font size = "4">
$$    \max\limits_{(\beta_0, \beta_j)} exp\left\{ \sum_{i=1}^n \left( y_{i} (\beta_{0} + \sum_{j=1}^p \beta_{j} x_{j} ) - ln \left(1 + e^{\beta_{0} + \sum\limits_{j=1}^p \beta_{j} x_{j}} \right)\right) \right\}$$
</font>
- TRV 1\% pour la sélection de variable


## Modèle linéaire avec régularisation

- GLM Bernoulli avec régularisation Lasso

- Modélisation de la probabilité de résignation avec régression logistique

- Estimateurs $\beta_{i}$ 

- Optimisation de l'hyperparamètre $\lambda$ 


## Modèle linéaire avec régularisation

### Optimisation de l'hyperparamètre $\lambda$


![](lambda_opti.jpg){width=1000px}

## Modèle linéaire avec régularisation

### Variables avec coeffcient nul de la régulation Lasso

<br/>

![](selection_lasso.jpg){width=800px}

## Modèles k plus proches voisins

<br/>

- Utilisation de la distance euclédienne

- Transformation des variables catégorielles non-ordonnées en variables binaires

- Transformation des variables ordonnées en numérique discrète (1, 2, ...)

- Prédiction de la probabilité de résignation par régression


## Modèles k plus proches voisins

### Optimisation de l'hyperparamètre k

![](knn_opti.jpg){width=700px}


## Arbre de classification

<ul>
<li> Processus de partitionnement récursif binaire
<li> Deux fonctions de perte testée
$$
\mathcal{L}_G = \sum_{k=1}^K \widehat{P}_{mk} (1 - \widehat{P}_{mk}) \qquad \mathcal{L}_D = - \sum_{k=1}^K \widehat{P}_{mk} \ln( \widehat{P}_{mk})
$$
<br/>
<li> Complexité de l'arbre sera optimisée en fonction de deux paramètres
    <ul>
    <li> paramètre de complexité (cp)
    <li> nombre minimal d'observations dans une feuille (minbucket) </li>
</li>
</ul>

## Arbre de classification 

### Optimisation des hyperparamètres

<br/>

![](arbre_opti.jpg){width=750px}


## Bagging

- Prévision obtenue par l'aggrégation d'arbres de classification

- Chaque arbre utilise l'indice de Gini

- Nombre d'arbre nécessaire

<center>
![](bag_nbtree.jpg){width=400px}
</center>


## Forêt aléatoire 

<ul>
<li> Taille de l'échantillon boostrap de 50\%

<li> Nombre d'arbre nécessaire

<center>
![](foret_nbtree.jpg){width=400px}
</center>

<li> Deux hyperparamètre à optimiser
    <ul>
    <li> taille minimal d'un noeud (nodesize)
    <li> nombre de prédicteurs choisi aléatoirement (mtry) </li>
</li>
</ul>


## Forêt aléatoire

### Optimisation des hyperparamètres

<br/>

<center>
![](foret_opti.jpg){width=350px}
</center>


## Boosting de gradient stochastique

<li> Amélioration à l'itération t
<font size = "4">
$$
   \sum_{i=1}^n \mathcal{L} \left\{ y_i, \widehat{f}_{t-1}(x_i) + \widehat{f}_{\text{arbre}}^t(x_i) \right\}
$$
</font>
<li> Avec fonction de perte 
<font size = "4">
$$
    \mathcal{L} = \sum_{k=1}^2 \widehat{P}_{ik} \ln( \widehat{P}_{ik})
$$
</font>

<li> Taux d'apprentissage <font size = "5"> $\lambda = 0.005$ </font>, sous-échantillonnage de 75\% 

<li> Deux hyperparamètre à optimiser
    <ul>
    <li> nombre d'arbre (n.trees)
    <li> profondeur maximal des arbres (d) </li>
</li>
</ul>

## Boosting de gradient stochastique

### Optimisation des hyperparamètres

```{r plot_gbm_opti, fig.height=3.5}
plot(gbmfit_Bern)
gbmfit_Bern$bestTune[1:2]
```






## Analyse exploratoire

```{r}
ggplot(data, aes(x=lapse, y=policy_age, col=polholder_BMCevol)) + 
    geom_boxplot()
```

## Analyse exploratoire
```{r}
ggplot(data, aes(x=policy_age, fill=lapse)) + 
    geom_bar(position = "dodge")
```
