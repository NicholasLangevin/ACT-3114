---
header-includes: \usepackage{multirow} \usepackage{amssymb} \usepackage{hyperref} \usepackage{booktabs} \hypersetup{ colorlinks=true,
  linkcolor=blue, filecolor=magenta, urlcolor=cyan}
bibliography: ../biblio.bib
bibliographystyle: apalike
nocite: | 
  @*
output:
  pdf_document: default
---
\newpage
\begin{flushright}
    \textbf{Équipe 8}
\end{flushright}

\begin{center}
    \vspace{2\baselineskip}
    Charles Comeau \\
    (111 185 421) \\
    \vspace{1\baselineskip}
    Nicholas Langevin \\
    (111 184 631) \\
    \vspace{1\baselineskip}
    Andréanne Larouche \\
    (111 190 518) \\
    \vspace{7\baselineskip}
    Apprentissage statistique en actuariat\\
    ACT-3114 \\
    \vspace{7\baselineskip}
    {\large
    \textbf{Analyse des données de renouvellement d'assurance}} \\
    \vspace{8\baselineskip}
    présenté à \\
    Marie-Pier Côté \\
    \vspace{9\baselineskip}
    École d’actuariat \\
    Université Laval \\
    27 février 2020
\end{center}


\newpage

\tableofcontents

```{r, setup, include=FALSE}
knitr::opts_chunk$set(fig.width = 5, echo=FALSE, message=FALSE, warning=FALSE,
fig.align="center")
```

```{r, LoadingPackages, include = FALSE}
library(plyr)
library(tidyverse)
library(pROC)
library(rpart)
library(rpart.plot)
library(caret)
library(glmnet)
require(randomForest)
source("../script/_utilityFunction.R")
load(file="../data/trainData.RData")
load(file="../data/testData.RData")
```

\newpage

# Modèle de base

Pour le modèle de base, nous utiliserons un modèle linéaire généralisé avec une distribution binomiale. plus précisément, il s'agit d'une distribution binomiale avec $m = 1$ donc une distribution Bernouilli. La valeur de y est de 1 lorsque l'assuré résigne et de 0 lorsqu,il renouvèle. On s'intéresse à modéliser la probabilité que l'asssuré ne renouvelle pas son contrat. Pour ce faire, le lien logistic sera utilisée pour faire le lien entre la probabilité et le prédicteur linéaire. Ainsi nous avons

\begin{align}
    \ln \frac{\pi_{res}}{1 - \pi_{res}} = \beta_0 + \sum_{i=1}^p \beta_i x_i,
\end{align}

où nous voulons maximiser la vraisemblance d'une bernouilli. Ainsi les valeurs des paramètres sont obtenue en maximisant l'équation suivante.

\begin{align}
    \max\limits_{(\beta_0, \beta_j)} exp\left\{ \sum_{i=1}^n \left( y_{i} (\beta_{0} + \sum_{j=1}^p \beta_{j} x_{j} ) - ln \left(1 + e^{\beta_{0} + \sum\limits_{j=1}^p \beta_{j} x_{j}} \right)\right) \right\}
\end{align}

Pour ce modèle de base, il n'a pas d'optimisation d'hyperparamètres. Par contre, il est pertinent d'effectuer une sélection des variables explicatives pour rendre le modèle moins complexe. Nous avons effectuer des tests du rapport de vraisemblance pour la sélection des variables. Un niveau de 99\% à été choisi pour ces tests. Au final, il y a 7 variables parmis les 19 qui ne sont **pas sélectionnées** pour le modèle de base les voici


\begin{itemize}
\item policy\_caruse: utilisation de l'auto
\item policy\_nbcontract: nombre de polices du contrat
\item vehicl\_agepurchase: âge du véhicule lors de l'achat
\item vehicl\_powerkw: puissance du véhicule
\item vehicl\_garage: type de stationnement
\item prem\_pure: prime des coûts espérés
\item prem\_index: Taux d'augmentation de prime 
\end{itemize}

C'est donc de dire que ces variables ne seront pas considérés pour les prévisions avec le modèle de base.

# Ajustement des modèles

## Modèle linéaire généralisé avec régularisation Lasso

```{r, lasso.bestTune}
load(file="../src/02-lasso/lasso.valid.dev.rds")
load(file="../src/02-lasso/lasso.valid.auc.rds")
load(file="../src/02-lasso/lasso.pred.dev.rds")
load(file="../src/02-lasso/lasso.pred.auc.rds")
```

Comme dans le cas d'un modèle généralisé (_GLM_), la distribution binomial à
été choisi pour modéliser la probabilité de renouvellement. De plus, le lien
_logistic_ à été utilisé. Si $\pi_{res}$ représente la probabilité que l'assuré
résigne sont contrat, alors le modèle peut être écrit comme
\begin{align}
    \ln \frac{\pi_{res}}{1 - \pi_{res}} = \beta_0 + \sum_{i=1}^p \beta_i x_i,
\end{align}
où les $(\beta_0, \beta_j)$ sont obtenue en minimisant l'équation suivant
\begin{align}
    \min\limits_{(\beta_0, \beta_j)} \sum_{i=1}^n (y_i - \beta_0 - \sum_{j=1}^p
    \beta_j x_j)^2 + \lambda \sum_{j=1}^p |\beta_j|.
\end{align}
La fonction de minimisation comprend le paramètre $\lambda$ qui doit être
déterminé d'avance. La valeur optimal à été choisi par validation croisée à
$10$ plis. Le \autoref{fig:lasso.valid} montre le resultat de celle-ci pour
deux metrique différentes, soit la _deviance_ d'une binomial et l'_AUC_.
Les deux valeurs optimales pour $\lambda$ sont 
`r format(lasso.valid.dev$lambda.min, digits=5, scientific = FALSE)` et 
`r format(lasso.valid.auc$lambda.min, digits=5, scientific = FALSE)`
respectivement.

\begin{figure}
\centering
\begin{minipage}{0.48\linewidth}
```{r, lasso.plotBestLambda.dev}
plot(lasso.valid.dev)
```
\end{minipage}
\hfill
\begin{minipage}{0.48\linewidth}
```{r, lasso.plotBestLambda.auc}
plot(lasso.valid.auc)
```
\end{minipage}
\caption{Résultats de la validation croisée à $10$ plis selon différentes
métriques pour déterminer le $\lambda$ optimal. Les valeurs optimales obtenues
sont de 
`r format(lasso.valid.dev$lambda.min, digits=5, scientific = FALSE)` pour la 
\emph{deviance} d'une binomial et de
`r format(lasso.valid.auc$lambda.min, digits=5, scientific = FALSE)` pour 
\emph{AUC}.}
\label{fig:lasso.valid}
\end{figure}

Selon la valeur optimal de $\lambda$ qui optimise chacune des métriques, les 
variables qui voient leurs coeficients ($\beta$) rétrécire à
$0$ sont similaire. Ces variables sont listé dans le 
\autoref{tbl:lasso.variable0}. Il est intérésant de voir que les variables
**prem\_pure** et **prem\_last** ne semble pas importantes, ce qui confirme 
l'hypothèse du premier rapport où la prime absolue n'est pas importante.
C'est pourquoi initialement la variable 
**prem\_index = prem\_final / prem\_last** avait été crée. 
Nous verrons plus tard que cette dernière est importante dans le modele d'arbre. 
Finalement, il est pertimant de mentionner que c'est prime pure qui est exclut
du modèle et non la prime final charché au client. Conséquament, ceci montre
que les caractéristiques du marché impact la probabilité de renouvellement, ce 
qui est logique puisque il est normal que le taux de rétention d'un assureur
soit impacté par sa compétivité dans le marché.

```{r, lasso.varShrinked, results='asis'}
lasso.names <- c("policy caruse", "prem last", "prem pure", "vehicl garage",
                 "vehicl region", "vehicl region", "vehicl region")
lasso.level <- c("private or freelance work", "-", "-", "street", "Region 03",
                 "Region 08", "Region 10")
dev.name <- c("x","x","x","x","x","x","x")
auc.name <- c("x","x","x"," ","x","x"," ")

lasso.names0 <- data.frame(Variable=lasso.names, Niveau=lasso.level,
                           Deviance=dev.name, AUC=auc.name)
Rmd_table(lasso.names0, label="tbl:lasso.variable0", 
          caption="Variables qui voient leur coeficient rétricire à $0$ (noté
          par un x). La colonne \\emph{deviance} représente les variables
          exclut par le $\\lambda$ optimal selon cette métrique et pareillement
          pour la colonne \\emph{AUC}.")
```

Pour déterminer si une prédiction est un résignation où un
renouvellement, il faut déterminer le seuil optimal qui maximise la sensitivité
et la spécificité. Celui-ci à été sélectionné selon le critère suivant
\begin{align}
    \min\{ (1-\text{sentitivité})^2 + (1-\text{spécificité})^2 \}.
\end{align}

```{r, lasso.confMatrix}
roc.dev <- roc(ifelse(testData$lapse == "resignation", 1, 0), as.numeric(lasso.pred.dev), plot=F, col="red")
result.coords.dev <- coords(roc.dev, "best", best.method="closest.topleft", ret=c("threshold", "accuracy", "specificity", "sensitivity"), transpose = TRUE)
spec.dev <- format(result.coords.dev, scientific=FALSE, digits=1)

roc.auc <- roc(ifelse(testData$lapse == "resignation", 1, 0), as.numeric(lasso.pred.auc), plot=F, col="red")
# plot(roc.auc, print.thres="best", print.thres.best.method="closest.topleft")
result.coords.auc <- coords(roc.auc, "best", best.method="closest.topleft", ret=c("threshold", "accuracy", "specificity", "sensitivity"), transpose = TRUE)
spec.auc <- format(result.coords.auc, scientific=FALSE, digits=1)


lasso.predBinaire.dev <- ifelse(lasso.pred.auc > result.coords.dev[1], 1, 0)
lasso.predBinaire.auc <- ifelse(lasso.pred.auc > result.coords.auc[1], 1, 0)

lasso.confMatrix.dev <- table(testData$lapse, lasso.predBinaire.dev)
lasso.confMatrix.auc <- table(testData$lapse, lasso.predBinaire.auc)
lasso.table.dev <- as.data.frame.matrix(lasso.confMatrix.dev)
lasso.table.auc <- as.data.frame.matrix(lasso.confMatrix.auc)
```

Ce critère représente le point le plus proche du coin haut gauche de la courbe
ROC. Puisque les 2 modèles on des courbes ROC similaire, le seuil optimial est
aussi similaire. Le \autoref{tbl:lasso.confMatrix} montre les tableaux de
confusion résultant. Dans le cas du modéle utilisant la _deviance_, la
sensitivity est de `r spec.dev[4]` et la spécificité est de `r spec.dev[3]`.
Dans le modèle utilisant la _AUC_, la sensitivity est de `r spec.dev[4]` et la
spécificité est de `r spec.dev[4]`. On remarque que l'erreur la plus fréquente
dans les deux cas est de prédire le un fausse résignation. Ceci pourrait causé
des erreurs de rentabilistion au renouvellement puisque la compagnie ne
passerait pas de grandes augmentations de prime à ces clients par **fausse**
peur de les perdes.

\begin{table}[!hb]
\centering
\caption{Tableau de confusion en utilisant le seuil optimal pour les deux 
différent modèle.}
\label{tbl:lasso.confMatrix}
\begin{minipage}{0.48\linewidth}
\begin{tabular}{l|cc}
\multicolumn{1}{c}{} & \multicolumn{2}{c}{Prédiction} \\
Deviance: & Renouvellement & Résignation \\
\hline
Renouvellement & `r lasso.table.dev[1, 1]` & `r lasso.table.dev[1, 2]` \\
Résignation    & `r lasso.table.dev[2, 1]` & `r lasso.table.dev[2, 2]` \\
\hline
\end{tabular}
\end{minipage}
\hfill
\begin{minipage}{0.48\linewidth}
\begin{tabular}{l|cc}
\multicolumn{1}{c}{} & \multicolumn{2}{c}{Prédiction} \\
AUC: & Renouvellement & Résignation \\
\hline
Renouvellement & `r lasso.table.auc[1, 1]` & `r lasso.table.auc[1, 2]` \\
Résignation    & `r lasso.table.auc[2, 1]` & `r lasso.table.auc[2, 2]` \\
\hline
\end{tabular}
\end{minipage}
\end{table}


\newpage

## k plus proches voisins

```{r, knn.bestTune}
load(file="../src/03-knn/fit.knn.rds")
load(file="../src/03-knn/knn.final.rds")
```

Le modèle des _k_ plus proches voisins calcule les prédictions en utilisant la
distance euclédienne, ce qui veut dire que les variables catégorielles
non-ordonées doivent être transformées en $(c-1)$ variables binaires. Aussi,
les variables catégorielles ordonnées ont été transformées en des variables
numériques disctrètes $(1, 2, 3,...)$. Le modèle des _k_ plus proches voisins
comprend un seul hyperparamètre, soit le nombre de voisins (_k_) à utilité pour
la prédiction. Ce choix a été optimizer en utilisant une validation croisé à 4
plis. La valeur de _k_ qui maximise l'aire sour la courbe ROC (_fonction
d’efficacité du récepteur_) est de `r as.numeric(fit.knn$bestTune)`. Ces
valeurs, pour chaque valeurs de _k_, sont présenté dans la
\autoref{tbl:knn.plot-bestTune}.


```{r, knn.plot_bestTune, results='asis', fig.asp=.62, fig.cap="\\label{tbl:knn.plot-bestTune} Valeurs de l'aire sous la courbe ROC en fonction de différentes valeurs de \\emph{k}"}
ggplot(fit.knn, highlight=TRUE) + 
    geom_line(col = "steelblue3") +
    geom_point(col = "steelblue3") + 
    xlab("k") + 
    ylab("AUC (Validation Croisée)")
    # geom_vline(xintercept=240, linetype = 2, col = "red")
```

```{r, knn.plot_ROC, results='asis', fig.height=4, fig.cap="\\label{tbl:knn.plot-ROC} TODO"}
# ROC(dataToNumeric(testData, "y"), modele.knn$pred, col="blue")
# roc(dataToNumeric(testData, "y"), modele.knn$pred, plot=TRUE)
```
\newpage

## Arbre de classification

```{r, tree.bestTune}
load(file="../src/04-tree/tree.T0.rds")
load(file="../src/04-tree/tree.gridResult.info.rds")
load(file="../src/04-tree/tree.gridResult.gini.rds")
load(file="../src/04-tree/tree.final.rds")
# fonction de perte
# procedure choix final
# presenter les hyperparamètre
```

Le modèle d'arbre de classification offre la possibilité d'utilisé deux
fonctions de perte différence. Si _K_ représente le nombre de classe, alors un
premier choix comme fonction de perte peut être l'indice de _Gini_, defini
comme
\begin{align}
    \mathcal{L}_G = \sum_{k=1}^K \widehat{P}_{mk} (1 - \widehat{P}_{mk}).
\end{align}
Dans un deuxième cas, il est possible d'utilisé la _deviance_ négative d'une
bernouilli (ou encore l'_entropie croisée_) defini comme
\begin{align}
    \mathcal{L}_D = \sum_{k=1}^K \widehat{P}_{mk} \ln( \widehat{P}_{mk}).
\end{align} 
La procédure d'optimisation des hyperparamètre à été effectuer pour chacune des
deux fonction de perte. En premier lieux, un arbre complet $T_0$ à été
entrainer par validation croisée en 10 plis. Celui-ci est défini comme un arbre
construit avec un paramètre de complexité (_cp_) à 0 ainsi que le nombre 
minimal d'observation dans chaque feuille (_minbucket_) à 1. Le
\autoref{fig:tree.plotArbreT0} présente l'erreur obtenu par validation croisée
pour certaine valeurs de _cp_. Selon cette metrique, le meilleur modèle serait 
l'arbre racine, ce qui signifie que la prédiction serait la même pour toutes
les données. La metrique _AUC_ sera considéré par la suite pour l'optimisation
des hyperparamètres.
```{r, tree.plotArbreT0, results='asis', fig.height=4, fig.cap="Résultats de la validation croisée pour un arbre complet $T_0$ utilisant \\emph{Gini} comme fonction de perte."}
plotcp(tree.T0, lty=2, col=2)
```

\newpage
Pour la suite, l'optimisation du _cp_ à été efectué sur plusieurs valeurs de
_minbucket_. La \autoref{tbl:tree.auc} montre les résultat de de l'aire sous la courbe ROC
(_AUC_) pour différente valeur de _minbucket_ en fonction du _cp_ optimal. À
droite, la fonction de perte utilisée est l'indice de _Gini_, alors qu'à
gauche, la fonction de perte utilité est l'_entropie croisée_. Ces valeurs on
été obtenu par validation croisée à 4 plis.


\begin{table}[!ht]
\caption{\emph{AUC} pour différente valeur de \emph{minbucket} en fonction du 
\emph{cp} optimal. À gauche, la fonction de perte utilisée est l'indice de 
\emph{Gini}, à droite l'\emph{entropie croisée}.}
\label{tbl:tree.auc}
\begin{minipage}{0.48\linewidth}
\centering
\begin{tabular}{ccc}
\hline
\multicolumn{3}{c}{Indice de Gini} \\
```{r, results='asis'}
Rmd_table(tree.gridResult.gini, caption="", label="",
          digits=c(0,0,6, 3), hline.after=c(-1, 0, 6, 7, 11), 
          only.contents = TRUE)
```
\end{tabular}
\end{minipage}
\hfill
\begin{minipage}{0.48\linewidth}
\centering
\begin{tabular}{ccc}
\hline
\multicolumn{3}{c}{Entropie croisée} \\
```{r, results='asis'}
Rmd_table(tree.gridResult.info, caption="", label="",
          digits=c(0,0,6,3), hline.after=c(-1, 0, 5, 6, 11), 
          only.contents = TRUE)
```
\end{tabular}
\end{minipage}
\end{table}

```{r, tree.choixHyperparametre, result=FALSE}
choixCP <- tree.gridResult.gini$cp[which.max(tree.gridResult.gini$ROC)]
choixMinbucket <- 
    tree.gridResult.gini$minbucket[which.max(tree.gridResult.gini$ROC)]
```
Les résultats, peut importe la fonction de perte utilisé, sont similaire dans
pour l'hyperparamètres _minbucket_. Par contre, le modèle utilisant l'indice de
_Gini_ est optimal pour une valeur de _cp_ plus élevé, résultant en un arbre
moins complexe. Il est donc meileur de prendre ce modele puisqu'il risque
potentiellement de moins sur-apprendre les données d'apprentissage. Ainsi, le
modèle choisis utilisira un _cp_ de `r format(choixCP, digits=5, scientific =
FALSE)`, un _minbucket_ de `r choixMinbucket` et utilisera l'indice de
_Gini_ comme fonction de perte.

```{r, results='asis', fig.height=4, fig.width=7}
rpart.plot(tree.final, type=1, fallen.leaves = FALSE, tweak=1.1)
```


\newpage

## Un ensemble d’arbres de décision agrégées par bagging

```{r, loading_bagging}
mod_base_bag <- readRDS("../src/05-Bagging/mod_bag_base.rds")
result_opt_bag <- readRDS("../src/05-Bagging/result_opt_bag_save.rds")
result_opt_bag <- as.data.frame(result_opt_bag)
colnames(result_opt_bag) <- c("nodesize", "AUC")

mod_base_forest <- readRDS("../src/06-RandomForest/mod_forest_base.rds")
rest <- readRDS("../src/06-RandomForest/mod_forest_base.rds")
result_opt_forest <- readRDS("../src/06-RandomForest/result_opt_rf_save.rds")
result_opt_forest <- as.data.frame(result_opt_forest)
colnames(result_opt_forest) <- c("nodesize", "mtry", "AUC")
```

Le modèle d'ensemble d’arbres de décision agrégées par bagging permet de d'obtenir
des prévisions à partir d'un nombre d'arbre de décision, chacun ajuster par un 
échantillon bootstrap des l'échantillon d'entrainement. Une prévision du bagging
correspondera à la classe prédite majoritaire (renouvellement ou non renouvellement)
par les arbres declassifications puisqu'il s'agit d'un problème de classification.
Chacun des arbres utilise l'indice de Gini comme fonction de perte. Nous avons fait
ce choix puisque qu'à la section précédente portant sur l'arbre de 
classification, l'indice de Gini a été préféré à l'entropie croisée.


Avant l'optimisation d'hyperparamètre il est nécessaire de déterminer un nombre
d'arbre suffisant pour améliorer les prévisions. Pour ce faire, nous ajustons
un modèle bagging avec un nombre d'arbre plus élevé que nécessaire avec
l'échantillon d'entrainement. Ce modèle bagging de base n'a pas de pas de
contrainte appliquée sur chacun des arbres puisque ce sera optimiser par
la suite. Pour déterminer le nombre d'arbre adéquat nous avons tracé un graphique
du taux d'erreur OOB en fonction du nombre d'arbres.

```{r, plot_OOB_bagging, results='asis', fig.height=4, fig.cap="Taux d'erreur OOB en fonction du nombre d'arbre B"}
plot(1:dim(mod_base_bag$err.rate)[1], mod_base_bag$err.rate[,1],
     type="l", xlab="B", ylab="Taux d'erreur OOB")
```

Comme on peut le voir dans le graphique, le taux d'erreur OOB se stabilise à partir
d'un nombre d'arbre de 100 et plus. Le nombre d'abre de notre bagging sera donc de 100.

\newpage

L'hyperparamètre qui sera optimisé par la suite pour augmenter les performances
du bagging est le paramètre de la taille minimale d'un noeud (nodesize) pour chacun
des arbres du modèle bagging. Des tailles de noeuds mininales partant de 2 allant
jusqu'à 40 seront testées. Pour l'optimisation, on s'intéressera à maximiser
la métrique AUC. Pour chaque taille de noeud, un AUC moyen sera calculée à partir
d'une validation croisée par 4 ensembles. Voici les résultats obtenus de la
validation croisée.

```{r, results='asis', fig.height=3.5}
colnames(result_opt_bag) <- c("nodesize", "AUC")
ggplot(result_opt_bag, aes(x=nodesize, y=AUC)) + 
    geom_line(col="darkred") + 
    geom_point(col="darkred") + 
    geom_vline(xintercept = 34, linetype="dashed", size=0.5, col="blue")
```

<!--
\begin{table}[!ht]
\begin{minipage}{0.23\linewidth}
\centering
\begin{tabular}{cc}
\hline
\multicolumn{2}{c}{} \\
```{r, results='asis'}
Rmd_table(result_opt_bag[1:10, ], caption="", label="",
          digits=c(0,0,4), hline.after=c(-1, 0, 10), 
          only.contents = TRUE)
```
\end{tabular}
\end{minipage}
\hfill
\begin{minipage}{0.23\linewidth}
\centering
\begin{tabular}{cc}
\hline
\multicolumn{2}{c}{} \\
```{r, results='asis'}
Rmd_table(result_opt_bag[11:20, ], caption="", label="",
          digits=c(0,0,4), hline.after=c(-1, 0, 10), 
          only.contents = TRUE)
```
\end{tabular}
\end{minipage}
\begin{minipage}{0.23\linewidth}
\centering
\begin{tabular}{cc}
\hline
\multicolumn{2}{c}{} \\
```{r, results='asis'}
Rmd_table(result_opt_bag[21:30, ], caption="", label="",
          digits=c(0,0,4), hline.after=c(-1, 0, 10), 
          only.contents = TRUE)
```
\end{tabular}
\end{minipage}
\hfill
\begin{minipage}{0.23\linewidth}
\centering
\begin{tabular}{cc}
\hline
\multicolumn{2}{c}{} \\
```{r, results='asis'}
Rmd_table(result_opt_bag[31:39, ], caption="", label="",
          digits=c(0,0,4), hline.after=c(-1, 0, 2, 3, 9), 
          only.contents = TRUE)
```
\end{tabular}
\end{minipage}
\end{table}
-->

On constate que l'AUC est maximisé lorsque nodesize prend une valeure 34. Le modèle d'ensemble d’arbres de décision agrégées par bagging choisi aura donc un nombre d'abres de 100 et une taille minimale d'un noeud pour les arbres de 34.  

\newpage

## Forêt aléatoire

La forêt aléatoire permet elle aussi d'obtenir des prévisions à partir de prévisions aggrégées d'arbre de classification. La fonction de perte utilisée à chaque arbre est encore l'indice de Gini pour la même raison mentionnée dans la section du Bagging. Cependant, un changement par rapport au bagging est la taille de l'échantillon boostrap pour ajuster les arbres. Puisque notre jeu de données est assez volumineux et que cette fois-ci, nous devrons optimiser deux hyperparamètres plutôt qu'un, nous avons choisi de prendre une taille d'échantillon bootsrap correspondant à 50\% de l'échantillon d'entraînement pour réduire les temps de calcul de l'optimisation.

Avant de procéder à l'optimisation il est encore nécessaire de déterminer un nombre d'arbre sufffisant pour la forêt. Pour ce faire, nous avons ajuster un modèle de forêt basique avec un nombre d'arbre plus élevé que nécessaire. Comme pour le bagging, pour déterminer le nombre d'arbre adéquatnous avons tracé un graphique du taux d'erreur OOB en fonction du nombre d'arbres.

```{r, plot_OOB_forest, results='asis', fig.height=4, fig.cap="Taux d'erreur OOB en fonction du nombre d'arbre B"}
plot(1:dim(mod_base_forest$err.rate)[1], mod_base_forest$err.rate[,1],
     type="l", xlab="B", ylab="Taux d'erreur OOB")
```

\newpage

Comme on peut le voir dans le graphique, le taux d'erreur OOB se stabilise à partir
d'un nombre d'arbre de 100 et plus comme le bagging. Le nombre d'arbres de notre forêt aléatoire sera donc de 100. Il y a deux hyperparamètres qui seront optimisé soient la taille minimale d'un noeud (nodesize) et le nombre de prédicteurs choisi de façon aléatoire (mtry) à chaque embranchement des arbres de la forêt aléatoire. Pour chaque nodesize allant de 5 jusqu'à 40 par multiple de 5, un mtry optimal est obtenu par validation croisée par 5 ensembles. Le métrique d'intérêt de l'optimisatiojn est l'AUC. Ce sont donc, des couples optimaux qui sont obtenu. Voici les résultats obtenus.

\begin{table}[!ht]
\centering
\begin{tabular}{ccc}
\hline
\multicolumn{3}{c}{} \\
```{r, results='asis'}
Rmd_table(result_opt_forest, caption="", label="",
          digits=c(0,0,0,4), hline.after=c(-1, 0, 3, 4, 8), 
          only.contents = TRUE)
```
\end{tabular}
\end{table}



On constate que le couples d'hyperparamètres qui a obtenu l'AUC le plus élevé correspond à un nodesize de 20 et un mtry de 10. En somme, la forest aléatoire choisi aura donc les caractéristiques suivantes: 

\begin{itemize}
\item La taille d'échantillon boostrap est de 50\% de l'échantillon d'entrainement
\item La forest aléatoire composée de 100 arbres
\item La taille minimale d'un noeud (nodesize) d'un arbre est de 20 observations
\item Le nombre de prédicteurs choisis de façon aléatoire (mtry) à chaque embranchement est de 10
\end{itemize}

\newpage

# Bibliographie
