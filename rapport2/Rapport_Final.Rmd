---
header-includes: \usepackage{multirow} \usepackage{multicol} \usepackage{amssymb} \usepackage{hyperref} \usepackage{booktabs} \hypersetup{ colorlinks=true,
  linkcolor=blue, filecolor=magenta, urlcolor=cyan}
bibliography: ../biblio.bib
bibliographystyle: apalike
nocite: | 
  @*
output:
  pdf_document: default
editor_options: 
  chunk_output_type: console
---
\newpage
\begin{flushright}
    \textbf{Équipe 8}
\end{flushright}

\begin{center}
    \vspace{2\baselineskip}
    Charles Comeau \\
    (111 185 421) \\
    \vspace{1\baselineskip}
    Nicholas Langevin \\
    (111 184 631) \\
    \vspace{1\baselineskip}
    Andréanne Larouche \\
    (111 190 518) \\
    \vspace{7\baselineskip}
    Apprentissage statistique en actuariat\\
    ACT-3114 \\
    \vspace{7\baselineskip}
    {\large
    \textbf{Analyse des données de renouvellement d'assurance}} \\
    \vspace{8\baselineskip}
    présenté à \\
    Marie-Pier Côté \\
    \vspace{9\baselineskip}
    École d’actuariat \\
    Université Laval \\
    27 février 2020
\end{center}


\newpage

\tableofcontents

```{r, setup, include=FALSE}
knitr::opts_chunk$set(fig.width = 5, echo=FALSE, message=FALSE, warning=FALSE,
fig.align="center")
```

```{r, LoadingPackages, include = FALSE}
library(plyr)
library(tidyverse)
library(pROC)
library(rpart)
library(rpart.plot)
library(caret)
library(glmnet)
require(randomForest)
source("../script/_utilityFunction.R")
load(file="../data/trainData.RData")
load(file="../data/testData.RData")
```

\newpage

# Introduction
Les contrats d'assurance IARD sont pour la plupart d'une durée d'un an;
conséquament, le renouvellement des polices est une étape répétitive pour les
assureurs. Il est important pour ceux-ci de bien prévoire combien d'assurés
resterons avec eux pour la prochaine années. Ces prévisions peuvent avoir de
l'importance sur les statégies de renouvellement, en autre, puisque plus un
assuré à des chances de renouveller, plus l'assureur voudra lui charger plus
cher pour augmenter sont profit. D'un autre coté, Cette prévision peut aussi
être utilisé dans les statégies nouvelles affaires puisque si beaucoup
d'assurés résigne leur police, la croissance en unité sera affecter et celle-ci
pourra prévoir des rabais pour les nouveaux assurées dans le but de compenser.

Notre travail se concentre sur la modélisation et la prédiction de la
probabilité de non-renouvellement des assurés. Pour ce faire, nous avons utilisé un
jeu de données, nommée _eudirectlapse_,  provenant du packetage _CASdataset_
(@CASdatasets). Ce jeu de données représente les primes de $23 060$ polices
avant et après le renouvellement ainsi que leurs status de renouvellement ou de
résignation. La base de données comprend aussi d'autres variables qui
caractérise chaques contrats comme l'age des conduteurs, le type de voiture
conducteurs etc. Finalement, cette base de données provient d'un assureur
inconnue et pour une années inconnues.

Finalement, dans le but de comparé correctement les modèles utilisés, 20% de la
base de données à été mis de coté pour servir comme données de test. Puisque
les données sont débalancées, la proportions de résignation à été conservé
autant dans les données d'entrainement que de test.

\newpage

# Modèle de base

```{r, loading_glm}
roc_res_optimal <- readRDS("../src/01-glm/roc_res_optimal.rds")
seuil_optimal_glm <- roc_res_optimal[1]
specificite_glm <- roc_res_optimal[2]
sensitivite_glm <- roc_res_optimal[3]
precision_glm <- roc_res_optimal[9]
a_glm <- roc_res_optimal[5]
d_glm <- roc_res_optimal[6]
b_glm <- roc_res_optimal[8]
c_glm <- roc_res_optimal[7]
```

Pour le modèle de base, nous utiliserons un modèle linéaire généralisé avec une distribution binomiale. plus précisément, il s'agit d'une distribution binomiale avec $m = 1$ donc une distribution Bernouilli. La valeur de y est de 1 lorsque l'assuré résigne et de 0 lorsqu,il renouvèle. On s'intéresse à modéliser la probabilité que l'asssuré ne renouvelle pas son contrat. Pour ce faire, le lien logistic sera utilisée pour faire le lien entre la probabilité et le prédicteur linéaire. Ainsi nous avons

\begin{align}
    \ln \frac{\pi_{res}}{1 - \pi_{res}} = \beta_0 + \sum_{i=1}^p \beta_i x_i,
\end{align}

où nous voulons maximiser la vraisemblance d'une bernouilli. Ainsi les valeurs des paramètres sont obtenue en maximisant l'équation suivante.

\begin{align}
    \max\limits_{(\beta_0, \beta_j)} exp\left\{ \sum_{i=1}^n \left( y_{i} (\beta_{0} + \sum_{j=1}^p \beta_{j} x_{j} ) - ln \left(1 + e^{\beta_{0} + \sum\limits_{j=1}^p \beta_{j} x_{j}} \right)\right) \right\}
\end{align}

Pour ce modèle de base, il n'a pas d'optimisation d'hyperparamètres. Par contre, il est pertinent d'effectuer une sélection des variables explicatives pour rendre le modèle moins complexe. Nous avons effectuer des tests du rapport de vraisemblance pour la sélection des variables. Un niveau de confiance de 99\% à été choisi pour ces tests. Au final, il y a 7 variables parmis les 19 qui ne sont **pas sélectionnées** pour le modèle de base les voici:

\begin{multicols}{2}
\begin{itemize}
\item policy\_caruse
\item policy\_nbcontract
\item prem\_pure
\item prem\_index
\end{itemize}
\columnbreak
\begin{itemize}
\item vehicl\_agepurchase
\item vehicl\_powerkw
\item vehicl\_garage
\end{itemize}
\end{multicols}

C'est donc de dire que ces variables ne seront pas considérés pour les prévisions avec le modèle de base. Le modèle retourne comme prévision une probabilité que le client résigne son contrat. Il est donc nécessaire de déterminer un seuil minimale pour lequel l'observation aura une prévision corrrespondant à une résignation et si la prévision est inférieure à ce seuil alors la prévision est un renouvellement. Il a été décidé d'utiliser le seuil optimal de la courbe ROC sur les données d'entrainement. C'est le seuil pour lequel le point sur la courbe ROC se retrouve le plus proche du coin supérieur gauche du graphique. Ce seuil est optimal pour un compromis entre les statitstiques de sensitivité, le taux de bonne classification des résignations, et de spécificité, le taux de bonne classification des renouvellements. Voici le tableau de confusion obtenu des données d'entrainement ainsi que des statistiques d'intérêt.

\begin{table}[!htb]
\centering
\begin{minipage}{0.48\linewidth}
\begin{tabular}{c|cc} 
\multicolumn{1}{c}{} & \multicolumn{2}{c}{Prédictions} \\
Observations & Renouvellement & Résignation \\
\hline Renouvellement & `r a_glm` & `r b_glm` \\
Résignation & `r c_glm` & `r d_glm` \\
\hline
\end{tabular}
\end{minipage}
\hfill
\begin{minipage}{0.48\linewidth}
\centering
\begin{tabular}{c|c} 
Statistiques & \% \\
\hline
Seuil optimal & `r round(seuil_optimal_glm * 100, 3)`  \\
Sensitivité & `r round(sensitivite_glm * 100, 3)` \\
Spécificité & `r round(specificite_glm * 100, 3)` \\
\hline
\end{tabular}
\end{minipage}
\end{table}

Les statistiques de sensitivité et de spécificité avoisines toutes les deux les 60\% dans le cas où nous prenons le seuil optimale. Cela veut dire que le modèle de base classifie avec un taux similaire les résignations et les renouvellement. Par contre on constate quand procédent ainsi, il y a un grand nombre de clients pour lesquels le modèle de base prédit une résignation alors qu'en fait se sont des clients enclins à renouveler. Il sera intéressant de voir si les autres modèles amilioreront cet aspect. Une comparaison avec les autres modèles sera établi avec l'échantillon test plus loin dans le rapport.   


\newpage

# Ajustement des modèles

## Modèle linéaire généralisé avec régularisation Lasso

```{r, lasso.bestTune}
load(file="../src/02-lasso/lasso.valid.dev.rds")
load(file="../src/02-lasso/lasso.valid.auc.rds")
load(file="../src/02-lasso/lasso.pred.dev.rds")
load(file="../src/02-lasso/lasso.pred.auc.rds")
load(file="../src/02-lasso/lasso.predTrain.dev.rds")
load(file="../src/02-lasso/lasso.predTrain.auc.rds")
```

Comme dans le cas d'un modèle généralisé (_GLM_), la distribution binomial à
été choisi pour modéliser la probabilité de résignation. De plus, le lien
_logistic_ à été utilisé. Si $\pi_{res}$ représente la probabilité que l'assuré
résigne sont contrat, alors le modèle peut être écrit comme
\begin{align}
    \ln \frac{\pi_{res}}{1 - \pi_{res}} = \beta_0 + \sum_{i=1}^p \beta_i x_i,
\end{align}
où les $(\beta_0, \beta_j)$ sont obtenue en minimisant l'équation suivant
\begin{align}
    \min\limits_{(\beta_0, \beta_j)} -\left[\frac{1}{N}\sum_{i=1}^n 
    y_i (\beta_0 + \sum_{i=1}^p \beta_i x_i) + 
    \log( 1 + e^{(\beta_0 + \sum_{i=1}^p \beta_i x_i)}) \right]
    + \lambda \sum_{j=1}^p |\beta_j|.
\end{align}
La fonction de minimisation comprend le paramètre $\lambda$ qui doit être
déterminé d'avance. La valeur optimale a été choisie par validation croisée à
$10$ plis. La \autoref{fig:lasso.valid} montre le résultat pour
deux métriques différentes, soit la _deviance_ d'une binomial et l' _AUC_.
Les deux valeurs optimales pour $\lambda$ sont 
`r format(lasso.valid.dev$lambda.min, digits=5, scientific = FALSE)` et 
`r format(lasso.valid.auc$lambda.min, digits=5, scientific = FALSE)`
respectivement.

\begin{figure}
\centering
\begin{minipage}{0.48\linewidth}
```{r, lasso.plotBestLambda.dev}
plot(lasso.valid.dev)
```
\end{minipage}
\hfill
\begin{minipage}{0.48\linewidth}
```{r, lasso.plotBestLambda.auc}
plot(lasso.valid.auc)
```
\end{minipage}
\caption{Résultats de la validation croisée à $10$ plis selon différentes
métriques pour déterminer le $\lambda$ optimal. Les valeurs optimales obtenues
sont de 
`r format(lasso.valid.dev$lambda.min, digits=5, scientific = FALSE)` pour la 
\emph{deviance} d'une binomial et de
`r format(lasso.valid.auc$lambda.min, digits=5, scientific = FALSE)` pour 
\emph{AUC}.}
\label{fig:lasso.valid}
\end{figure}

Selon la valeur optimal de $\lambda$ qui optimise chacune des métriques, les
variables qui voient leurs coefficients ($\beta$) rétrécir à $0$ sont
similaires. Ces variables sont listées dans le \autoref{tbl:lasso.variable0}.
Il est intéressant de voir que les variables *prem_pure* et *prem_last*
ne semblent pas importantes, ce qui confirme l'hypothèse du premier rapport où
la prime absolue n'est pas importante.  C'est pourquoi initialement la variable
*prem_index = prem.final / prem_last* avait été crée.  Nous verrons plus
tard que cette dernière est importante dans le modèle d'arbre.  Finalement, il
est pertinent de mentionner que c'est la variable représentant la prime pure
qui est exclut du modèle et non la variable contenant la prime finale chargée
au client, qui inclut probablement des rabais/surcharge en fonction du marché.
Conséquemment, ceci montre que les caractéristiques du marché impacte la
probabilité de non-renouvellement, ce qui est logique puisqu'il est normal que le
taux de rétention d'un assureur soit impacté par sa compétivité dans le marché.

```{r, lasso.varShrinked, results='asis'}
lasso.names <- c("policy caruse", "prem last", "prem pure", "vehicl garage",
                 "vehicl region", "vehicl region", "vehicl region")
lasso.level <- c("private or freelance work", "-", "-", "street", "Region 03",
                 "Region 08", "Region 10")
dev.name <- c("x","x","x","x","x","x","x")
auc.name <- c("x","x","x"," ","x","x"," ")
lasso.names0 <- data.frame(Variable=lasso.names, Niveau=lasso.level,
                           Deviance=dev.name, AUC=auc.name)
Rmd_table(lasso.names0, label="tbl:lasso.variable0", 
          caption="Variables qui voient leur coeficient rétricire à $0$ (noté
          par un x). La colonne \\emph{deviance} représente les variables
          exclut par le $\\lambda$ optimal selon cette métrique et pareillement
          pour la colonne \\emph{AUC}.")
```

Pour déterminer si une prédiction est à résignation ou à
renouvellement, il faut déterminer le seuil optimal qui maximise la sensitivité
et la spécificité. Celui-ci a été sélectionné selon le critère suivant
\begin{align}
    \min\{ (1-\text{sentitivité})^2 + (1-\text{spécificité})^2 \}.
\end{align}

```{r, lasso.confMatrix}
roc.dev <- roc(ifelse(testData$lapse == "resignation", 1, 0), as.numeric(lasso.pred.dev), plot=F, col="red")
result.coords.dev <- coords(roc.dev, "best", best.method="closest.topleft", ret=c("threshold", "accuracy", "specificity", "sensitivity"), transpose = TRUE)
spec.dev <- format(result.coords.dev, scientific=FALSE, digits=1)
roc.auc <- roc(ifelse(testData$lapse == "resignation", 1, 0), as.numeric(lasso.pred.auc), plot=F, col="red")
# plot(roc.auc, print.thres="best", print.thres.best.method="closest.topleft")
result.coords.auc <- coords(roc.auc, "best", best.method="closest.topleft", ret=c("threshold", "accuracy", "specificity", "sensitivity"), transpose = TRUE)
spec.auc <- format(result.coords.auc, scientific=FALSE, digits=1)
lasso.predBinaire.dev <- ifelse(lasso.predTrain.auc > result.coords.dev[1], 1, 0)
lasso.predBinaire.auc <- ifelse(lasso.predTrain.auc > result.coords.auc[1], 1, 0)
lasso.confMatrix.dev <- table(trainData$lapse, lasso.predBinaire.dev)
lasso.confMatrix.auc <- table(trainData$lapse, lasso.predBinaire.auc)
lasso.table.dev <- as.data.frame.matrix(lasso.confMatrix.dev)
lasso.table.auc <- as.data.frame.matrix(lasso.confMatrix.auc)
```

Ce critère représente le point le plus proche du coin haut gauche de la courbe
ROC. Puisque les 2 modèles ont des courbes ROC similaires, le seuil optimal est
aussi similaire. Le \autoref{tbl:lasso.confMatrix} montre les tableaux de
confusion résultants. Dans le cas du modèle utilisant la _deviance_, la
sensitivité est de `r spec.dev[4]` et la spécificité est de `r spec.dev[3]`.
Dans le modèle utilisant l' _AUC_, la sensitivité est de `r spec.dev[4]` et la
spécificité est de `r spec.dev[4]`. On remarque que l'erreur la plus fréquente
dans les deux cas est de prédire faussement résignation. Ceci pourrait causé
des erreurs de rentabilisation au renouvellement puisque la compagnie ne
passerait pas de grandes augmentations de prime à ces clients par **fausse**
peur que ceux-ci résigne leur contrat.

\begin{table}[!hb]
\centering
\caption{Tableau de confusion en utilisant le seuil optimal pour les deux 
différent modèle.}
\label{tbl:lasso.confMatrix}
\begin{minipage}{0.48\linewidth}
\begin{tabular}{l|cc}
\multicolumn{1}{c}{} & \multicolumn{2}{c}{Prédiction} \\
Deviance: & Renouvellement & Résignation \\
\hline
Renouvellement & `r lasso.table.dev[1, 1]` & `r lasso.table.dev[1, 2]` \\
Résignation    & `r lasso.table.dev[2, 1]` & `r lasso.table.dev[2, 2]` \\
\hline
\end{tabular}
\end{minipage}
\hfill
\begin{minipage}{0.48\linewidth}
\begin{tabular}{l|cc}
\multicolumn{1}{c}{} & \multicolumn{2}{c}{Prédiction} \\
AUC: & Renouvellement & Résignation \\
\hline
Renouvellement & `r lasso.table.auc[1, 1]` & `r lasso.table.auc[1, 2]` \\
Résignation    & `r lasso.table.auc[2, 1]` & `r lasso.table.auc[2, 2]` \\
\hline
\end{tabular}
\end{minipage}
\end{table}


\newpage

## k plus proches voisins

```{r, knn.bestTune}
load(file="../src/03-knn/fit.knn.rds")
load(file="../src/03-knn/knn.final.rds")
```

Le modèle des _k_ plus proches voisins calcule les prédictions en utilisant la
distance euclédienne, ce qui veut dire que les variables catégorielles
non-ordonnées doivent être transformées en $(c-1)$ variables binaires. Aussi,
les variables catégorielles ordonnées ont été transformées en des variables
numériques disctrètes $(1, 2, 3,...)$. Le modèle des _k_ plus proches voisins
comprend un seul hyperparamètre, soit le nombre de voisins (_k_) à utilisé pour
la prédiction. Ce choix a été optimisé en utilisant une validation croisée à 4
plis. La valeur de _k_ qui maximise l'aire sour la courbe ROC est de `r as.numeric(fit.knn$bestTune)`. Ces
valeurs, pour chaque valeurs de _k_, sont présenté dans la
\autoref{tbl:knn.plot-bestTune}.


```{r, knn.plot_bestTune, results='asis', fig.asp=.62, fig.cap="\\label{tbl:knn.plot-bestTune} Valeurs de l'aire sous la courbe ROC en fonction de différentes valeurs de \\emph{k}"}
ggplot(fit.knn, highlight=TRUE) + 
    geom_line(col = "steelblue3") +
    geom_point(col = "steelblue3") + 
    xlab("k") + 
    ylab("AUC (Validation Croisée)") + 
    theme_bw()
    # geom_vline(xintercept=240, linetype = 2, col = "red")
```
Les prédictions pour les données test qui serviront à comparer les modèles
seront classifier en fonction de la classe majoritaire des 
`r as.numeric(fit.knn$bestTune)` obervations les plus proches. Puisque nous
avons des données débalancées, ce type de modèle pourrait avoir des 
prévision médiocre puisque il va être rare plus de 50% soit des résignations
dans les plus proches voisins.

\newpage

## Arbre de classification

```{r, tree.bestTune}
load(file="../src/04-tree/tree.T0.rds")
load(file="../src/04-tree/tree.gridResult.info.rds")
load(file="../src/04-tree/tree.gridResult.gini.rds")
load(file="../src/04-tree/tree.final.rds")
# fonction de perte
# procedure choix final
# presenter les hyperparamètre
```

Le modèle d'arbre de classification offre la possibilité d'utilisé deux
fonctions de perte différence. Si _K_ représente le nombre de classe, alors un
premier choix comme fonction de perte peut être l' _indice de Gini_, defini
comme
\begin{align}
    \mathcal{L}_G = \sum_{k=1}^K \widehat{P}_{mk} (1 - \widehat{P}_{mk}).
\end{align}
Dans un deuxième cas, il est possible d'utiliser la _deviance_ négative d'une
loi bernoulli (ou encore l'_entropie croisée_) defini comme
\begin{align}
    \mathcal{L}_D = \sum_{k=1}^K \widehat{P}_{mk} \ln( \widehat{P}_{mk}).
\end{align} 
La procédure d'optimisation des hyperparamètres a été effectuée pour chacune des
deux fonctions de perte. En premier lieu, un arbre complet $T_0$ a été
entrainé par validation croisée en 10 plis. Celui-ci est défini comme un arbre
construit avec un paramètre de complexité (_cp_) à 0 ainsi qu'un nombre 
minimal d'observation dans chaque feuille (_minbucket_) à 1. La
\autoref{fig:tree.plotArbreT0} présente l'erreur obtenue par validation croisée
pour certaines valeurs de _cp_. Selon cette métrique, le meilleur modèle serait 
l'arbre racine, ce qui signifie que la prédiction serait la même pour toutes
les données. La métrique _AUC_ sera considérée par la suite pour l'optimisation
des hyperparamètres.
```{r, tree.plotArbreT0, results='asis', fig.height=4, fig.cap="Résultats de la validation croisée pour un arbre complet $T_0$ utilisant \\emph{Gini} comme fonction de perte."}
plotcp(tree.T0, lty=2, col=2)
```

\newpage
Pour la suite, l'optimisation du _cp_ a été effectuée sur plusieurs valeurs de
_minbucket_. La \autoref{tbl:tree.auc} montre les résultats de l'aire sous la courbe ROC
(_AUC_) pour différente valeur de _minbucket_ en fonction du _cp_ optimal. À
droite, la fonction de perte utilisée est l' _indice de Gini_, alors qu'à
gauche, la fonction de perte utilitée est l' _entropie croisée_. Ces valeurs on
été obtenues par validation croisée à 4 plis.


\begin{table}[!ht]
\caption{\emph{AUC} pour différentes valeurs de \emph{minbucket} en fonction du 
\emph{cp} optimal. À gauche, la fonction de perte utilisée est l'indice de 
\emph{Gini} et à droite l'\emph{entropie croisée}.}
\label{tbl:tree.auc}
\begin{minipage}{0.48\linewidth}
\centering
\begin{tabular}{ccc}
\hline
\multicolumn{3}{c}{Indice de Gini} \\
```{r, results='asis'}
Rmd_table(tree.gridResult.gini, caption="", label="",
          digits=c(0,0,6, 3), hline.after=c(-1, 0, 6, 7, 11), 
          only.contents = TRUE)
```
\end{tabular}
\end{minipage}
\hfill
\begin{minipage}{0.48\linewidth}
\centering
\begin{tabular}{ccc}
\hline
\multicolumn{3}{c}{Entropie croisée} \\
```{r, results='asis'}
Rmd_table(tree.gridResult.info, caption="", label="",
          digits=c(0,0,6,3), hline.after=c(-1, 0, 5, 6, 11), 
          only.contents = TRUE)
```
\end{tabular}
\end{minipage}
\end{table}

```{r, tree.choixHyperparametre, result=FALSE}
choixCP <- tree.gridResult.gini$cp[which.max(tree.gridResult.gini$ROC)]
choixMinbucket <- 
    tree.gridResult.gini$minbucket[which.max(tree.gridResult.gini$ROC)]
```

Les résultats, peut importe la fonction de perte utilisée, sont similaires dans
pour l'hyperparamètre _minbucket_. Par contre, le modèle utilisant l'_indice de Gini_ 
est optimal pour une valeur de _cp_ plus élevée, résultant en un arbre
moins complexe. Il est donc préférable de prendre ce modèle puisqu'il risque
potentiellement de moins faire de surapprentissage sur les données d'apprentissage. Ainsi, le
modèle choisi utilisira un _cp_ de `r format(choixCP, digits=5, scientific =FALSE)`, 
un _minbucket_ de `r choixMinbucket` et utilisera l' _indice de Gini_ comme fonction de perte.
La figure \autoref{fig:arbre} illustre l'arbre résultant.

```{r, results='asis', fig.height=4, fig.width=7, fig.cap="\\label{fig:arbre} Arbre optimal utilisant un cp de `r format(choixCP, digits=5, scientific =FALSE)`, un minbucket de `r choixMinbucket` et l'indice de Gini comme fonction de perte."}
rpart.plot(tree.final, type=1, fallen.leaves = FALSE, tweak=1.1)
```


\newpage

## Un ensemble d’arbres de décision agrégées par bagging

```{r, loading_bagging}
mod_base_bag <- readRDS("../src/05-Bagging/mod_bag_base.rds")
result_opt_bag <- readRDS("../src/05-Bagging/result_opt_bag_save.rds")
mod_bag_final <- readRDS("../src/05-Bagging/mod_bagging.rds")
result_opt_bag <- as.data.frame(result_opt_bag)
colnames(result_opt_bag) <- c("nodesize", "AUC")
mod_base_forest <- readRDS("../src/06-RandomForest/mod_forest_base.rds")
mod_forest_fin <- readRDS("../src/06-RandomForest/mod_forest.rds")
rest <- readRDS("../src/06-RandomForest/mod_forest_base.rds")
result_opt_forest <- readRDS("../src/06-RandomForest/result_opt_rf_save.rds")
result_opt_forest <- as.data.frame(result_opt_forest)
colnames(result_opt_forest) <- c("nodesize", "mtry", "AUC")
```

Le modèle d'ensemble d’arbres de décision agrégées par bagging permet d'obtenir
des prévisions à partir d'un nombre d'arbre de décision, chacun ajusté par un 
échantillon bootstrap de l'échantillon d'entrainement. Une prévision du bagging
correspondera à la classe prédite majoritaire (renouvellement ou résignation)
par les arbres de classifications puisqu'il s'agit d'un problème de classification.
Chacun des arbres utilise l' _indice de Gini_ comme fonction de perte. Nous avons fait
ce choix puisque qu'à la section précédente portant sur l'arbre de 
classification, on a pu démontrer que l' _indice de Gini_ était préférable à l'entropie croisée
pour notre jeu de donnée.


Avant l'optimisation d'hyperparamètre, il est nécessaire de déterminer un nombre
d'arbre suffisant pour améliorer les prévisions. Pour ce faire, nous ajustons
un modèle bagging avec un nombre d'arbre plus élevé que nécessaire avec
l'échantillon d'entrainement. Ce modèle bagging de base n'a pas de pas de
contrainte appliquée sur chacun des arbres puisque ce sera optimiser par
la suite. Pour déterminer le nombre d'arbre adéquat nous avons tracer un graphique
du taux d'erreur _OOB_ en fonction du nombre d'arbres _T_.

```{r, plot_OOB_bagging, results='asis', fig.height=4, fig.cap="Taux d'erreur OOB en fonction du nombre d'arbre B"}
plot(1:dim(mod_base_bag$err.rate)[1], mod_base_bag$err.rate[,1],
     type="l", xlab="B", ylab="Taux d'erreur OOB")
```

Comme on peut le voir dans le graphique, le taux d'erreur _OOB_ se stabilise à partir
d'un nombre d'arbre de 100 et plus. Le nombre d'abre de notre bagging sera donc de 100.

\newpage

L'hyperparamètre qui sera optimisé par la suite pour augmenter les performances
du bagging est le paramètre de la taille minimale d'un noeud (nodesize) pour chacun
des arbres du modèle bagging. Des tailles de noeuds minimales partant de 2 allant
jusqu'à 40 seront testées. Pour l'optimisation, on s'intéressera à maximiser
la métrique AUC. Pour chaque taille de noeud, un AUC moyen sera calculée à partir
d'une validation croisée par 4 ensembles. Voici les résultats obtenus de la
validation croisée.

```{r, results='asis', fig.height=3.5}
colnames(result_opt_bag) <- c("nodesize", "AUC")
ggplot(result_opt_bag, aes(x=nodesize, y=AUC)) + 
    geom_line(col="darkred") + 
    geom_point(col="darkred") + 
    geom_vline(xintercept = 34, linetype="dashed", size=0.5, col="blue")
```

<!--
\begin{table}[!ht]
\begin{minipage}{0.23\linewidth}
\centering
\begin{tabular}{cc}
\hline
\multicolumn{2}{c}{} \\
```{r, results='asis'}
Rmd_table(result_opt_bag[1:10, ], caption="", label="",
          digits=c(0,0,4), hline.after=c(-1, 0, 10), 
          only.contents = TRUE)
```
\end{tabular}
\end{minipage}
\hfill
\begin{minipage}{0.23\linewidth}
\centering
\begin{tabular}{cc}
\hline
\multicolumn{2}{c}{} \\
```{r, results='asis'}
Rmd_table(result_opt_bag[11:20, ], caption="", label="",
          digits=c(0,0,4), hline.after=c(-1, 0, 10), 
          only.contents = TRUE)
```
\end{tabular}
\end{minipage}
\begin{minipage}{0.23\linewidth}
\centering
\begin{tabular}{cc}
\hline
\multicolumn{2}{c}{} \\
```{r, results='asis'}
Rmd_table(result_opt_bag[21:30, ], caption="", label="",
          digits=c(0,0,4), hline.after=c(-1, 0, 10), 
          only.contents = TRUE)
```
\end{tabular}
\end{minipage}
\hfill
\begin{minipage}{0.23\linewidth}
\centering
\begin{tabular}{cc}
\hline
\multicolumn{2}{c}{} \\
```{r, results='asis'}
Rmd_table(result_opt_bag[31:39, ], caption="", label="",
          digits=c(0,0,4), hline.after=c(-1, 0, 2, 3, 9), 
          only.contents = TRUE)
```
\end{tabular}
\end{minipage}
\end{table}
-->

On constate que l'AUC est maximisé lorsque _nodesize_ prend une valeur de 34. Le modèle d'ensemble d’arbres de décision agrégées par bagging choisit aura donc un nombre d'abres de 100 et une taille minimale d'un noeud pour les arbres de 34.  

\newpage

## Forêt aléatoire

La forêt aléatoire permet elle aussi d'obtenir des prévisions à partir de prévisions aggrégées d'arbre de classification. La fonction de perte utilisée à chaque arbre est encore l' _indice de Gini_ pour la même raison mentionnée précedemment. Cependant, un changement par rapport au bagging est la taille de l'échantillon boostrap pour ajuster les arbres. Puisque notre jeu de données est assez volumineux et que cette fois-ci, nous devrons optimiser deux hyperparamètres plutôt qu'un, nous avons choisi de prendre une taille d'échantillon bootsrap correspondant à 50\% de l'échantillon d'entraînement pour réduire les temps de calcul de l'optimisation.

Avant de procéder à l'optimisation, il est encore nécessaire de déterminer un nombre d'arbre sufffisant pour la forêt. Pour ce faire, nous avons ajusté un modèle de forêt classique avec un nombre d'arbre plus élevé que nécessaire. Comme pour le bagging, pour déterminer le nombre d'arbre adéquat, nous avons tracé un graphique du taux d'erreur _OOB_ en fonction du nombre d'arbres _T_.

```{r, plot_OOB_forest, results='asis', fig.height=4, fig.cap="Taux d'erreur OOB en fonction du nombre d'arbre B"}
plot(1:dim(mod_base_forest$err.rate)[1], mod_base_forest$err.rate[,1],
     type="l", xlab="B", ylab="Taux d'erreur OOB")
```

\newpage

Comme on peut le voir dans le graphique, le taux d'erreur _OOB_ se stabilise à partir
d'un nombre d'arbres de 100 et plus comme le bagging. Le nombre d'arbres de notre forêt aléatoire sera donc de 100. Il y a deux hyperparamètres qui seront optimisés soient la taille minimale d'un noeud  (nodesize) et le nombre de prédicteurs choisi de façon aléatoire (mtry) à chaque noeud de la forêt aléatoire. Pour chaque _nodesize_ allant de 5 jusqu'à 40 par multiple de 5, un _mtry_ optimal est obtenu par validation croisée à 5 plis. Le métrique d'intérêt de l'optimisation est l' _AUC_. Ce sont donc, des couples optimaux qui sont obtenus. Voici les résultats obtenus.

\begin{table}[!ht]
\centering
\begin{tabular}{ccc}
\hline
\multicolumn{3}{c}{} \\
```{r, results='asis'}
Rmd_table(result_opt_forest, caption="", label="",
          digits=c(0,0,0,4), hline.after=c(-1, 0, 3, 4, 8), 
          only.contents = TRUE)
```
\end{tabular}
\end{table}



On constate que le couple d'hyperparamètres qui a obtenu l' _AUC_ le plus élevé correspond à un _nodesize_ de 20 et un _mtry_ de 10. En somme, la forêt aléatoire choisie aura donc les caractéristiques suivantes: 

\begin{itemize}
\item La taille d'échantillon boostrap est de 50\% de l'échantillon d'entrainement
\item La forêt aléatoire est composée de 100 arbres 
\item La taille minimale d'un noeud (nodesize) d'un arbre est de 20 observations
\item Le nombre de prédicteurs choisis de façon aléatoire (mtry) à chaque embranchement est de 10
\end{itemize}


\newpage

## Boosting de gradient stochastique

```{r, gbm.modfit1}
load(file="../src/07-gbm/plotoptimisation.rds")
load(file = "../src/07-gbm/gbm_opti_ROC.rds")
load(file="../src/07-gbm/gbm_Bern_final.rds")
```

Le modèle de boosting de gradient est un modèle de boosting généralisé pour toute fonction de perte d'intérêt. Dans notre cas, nous utiliserons le boosting de gradient dans un cas de classification. Ainsi, la fonction de perte d'intérêt est la _déviance de la loi Bernoulli_. À ces fins, les données ont dû être temporairement transformées en données booléennes de type 0 et 1 pour l'élaboration du modèle.

Il est à noter que l'idée générale est d'améliorer la prévision le plus possible à l'itération _t_ en trouvant un arbre $\widehat{f}_{\text{arbre}}^t$ afin de minimiser la perte 
\begin{align}
   \sum_{i=1}^n \mathcal{L} \left\{ y_i, \widehat{f}_{t-1}(x_i) + \widehat{f}_{\text{arbre}}^t(x_i) \right\}.
\end{align} 

La perte ce retrouve minimisé car à chaque itération, un pas de plus est effectué dans la direction du gradient négatif. De plus, étant donné qu'on utilise la déviance négative d'une loi bernouilli comme fonction de perte,
\begin{align}
    \mathcal{L} = \sum_{k=1}^2 \widehat{P}_{ik} \ln( \widehat{P}_{ik}).
\end{align} 

Ce modèle choisit un sous-échantillon de taille inférieur à $n$ pour ajuster l'arbre au lieu d'utiliser un échantillon de taille simillaire à l'échantillon d'entrainement à chaque fois. Cette manière de procéder permet de réduire le temps d'entrainement et peut améliorer la précision des prévisions étant donné que ce ne sera pas toujours les mêmes données qui risquent de ce retrouver dans chacun des arbres.

La procédure d'optimisation des hyperparamètres a été effectuée pour la fonction de perte visée. Les hyperparamètres sont **n.trees**, **interaction.depth**, **shrinkage** et **n.minobsinnode** représentant repectivement le nombre d'arbres dans le boosting, la profondeur maximale de l'arbre, le taux d'apprentissage $\lambda$ et le nombre d'observations minimal par noeud. On optimisera seulement **n.trees** et **interaction.depth** car les deux autres hyperparamètres peuvent être choisit facilement dans le but d'avoir un temps d'exécution raisonnable. Selon les tests effectués au préalable on prendra un $\lambda = 0.005$ et un $n.minobsinnode = 20$.

L'optimisation des deux hyperparamètres restants est ensuite fait à partir de la validation croisée sur 4 ensembles. C'est une méthode d'optimisation qui permet de trouver les hyperparamètres optimaux sur chacun des plis pour ensuite choisir les hyperparamètres optimaux sur l'ensemble des données d'entrainement. Le choix se fera à l'aide de la métrique _ROC_. Le choix des paramètres est donc effectué selon l'aire sour la courbe ROC ( _AUC_) obtenue la plus élevée. On observe ainsi aisément à l'aide de la \autoref{fig:gbm.plotoptimisation} que le modèle choisit utilisera un $n.trees(T) =$ `r gbmfit_Bern$bestTune["n.trees"]`, un $interaction.depth(d) =$ `r gbmfit_Bern$bestTune["interaction.depth"]` et comme indiqué précédemment, un $shrinkage(\lambda) = 0.005$, un $n.minobsinnode = 20$ et la déviance négative d'une loi bernoulli comme fonction de perte. C'est avec ces valeurs que le modèle atteint la plus haute performance pour un temps de calcul raisonnable. Le graphique nous indique bien le choix des valeurs car on choisit ce qui permet au modèle d'atteindre la plus haute valeur pour l' _AUC_. Il est à noter que pour une meilleure performance le taux d'apprentissage aurait été plus faible et le nombre d'arbres plus élevé ce qui demande une espace de stockage et un temps de calcul beaucoup plus important. 

\newpage

```{r, gbm.plotoptimisation, results='asis', fig.height=4, fig.cap="Résultats obtenu pour l'optimisation des paramètres à partir de la fonction train en R."}
plot(gbmfit_Bern)
```


\newpage

# Comparaison des modèles

```{r, Load_roc_auc, include = FALSE}
load(file="../src/01-glm/roc.rds")
load(file="../src/01-glm/auc.rds")
load(file="../src/02-lasso/roc.rds")
load(file="../src/02-lasso/auc.rds")
load(file="../src/07-gbm/roc.rds")
roc_knn <- roc(dataToNumeric(testData, "y"), knn.final$pred)
roc_tree <- roc(dataToNumeric(testData, "y"),  predict(tree.final, newdata = testData)[,2])
roc_Bagging <- roc(testData$lapse, predict(mod_bag_final, newdata = testData, type="prob")[,2])
roc_RandomForest <- roc(testData$lapse,predict(mod_forest_fin, newdata = testData, type="prob")[,2])
auc_knn <- as.numeric(roc_knn$auc)
auc_tree <- as.numeric(roc_tree$auc)
auc_Bagging <- as.numeric(roc_Bagging$auc)
auc_RandomForest <- as.numeric(roc_RandomForest$auc)
auc_gbm <- as.numeric(roc_gbm$auc)
auc_result <- data.frame("Modèles"=c("Modèle de base GLM", "Modèle linéaire avec régularisation Lasso", "modèle des k plus proches voisins",  "Arbre de décision", "Ensemble d'arbres de décision agrégées par bagging", "forêt aléatoire", "Modèle de gradient boosting"), AUC=c(auc_GLM, auc_lasso, auc_knn, auc_tree, auc_Bagging, auc_RandomForest, auc_gbm))
```

Dans cette section, il sera question de comparer la performance prédictive des différents modèles. Pour ce faire, nous analyserons la performance de la prévison sur les données test à l'aide de la courbe ROC et de la valeur de l'AUC, soit l'aire sous la courbe ROC. 

Les modèles ayant l'AUC la plus élevée sont les modèles ayant la performance de prévision la plus élevé basé sur cette métrique. La \autoref{fig:plot_ROC} illustre les différentes courbes ROC obtenu pour les différents modèles et le \autoref{tbl:tableau-AUC} présente les valeurs d'AUC qui découle de ces courbes.

```{r tableau_AUC, results="asis"}
Rmd_table(auc_result, caption = "Aire sous la courbe ROC pour chacun des différents modèles", label = "tbl:tableau-AUC", align = c("l","l","r"))
```

```{r plot_ROC, results='asis', fig.height=4, fig.cap="Courbe ROC pour chacun des différents modèles"}
plot(roc_GLM, col = "red")
plot(roc_lasso, col="blue", add=T)
plot(roc_knn, col="yellow", add=T) 
plot(roc_tree,col="green", add=T)
plot(roc_Bagging, col="pink", add=T)
plot(roc_RandomForest, col="orange", add=T)
plot(roc_gbm, col="purple", add=T)
legend("bottomright", c("glm", "Lasso", "knn", "Arbre", "Bagging", "Forêt", "gbm"), lty=1, 
       col = c("red", "blue", "yellow", "green", "pink", "orange", "purple"), cex = 0.7)
```

La courbe ROC est défini comme étant la sensitivité en fonction du faux négatifs. Dans le but d'avoir une bonne performance prédictive, on recherche à maximiser la sensitivité et la spécificité, ce qui se traduit en une courbe ce rapprochant le plus possible du coin supérieur gauche. En ayant utilisé cette métrique pour classifier la performance, on peut baser notre choix sur les modèles ayant l'AUC le plus élevée. De ce sens, on peut conclure que les modèles ont une bonne puissance de prévision car leurs valeurs d'AUC sont tous supérieur à  `r min(auc_result$AUC)`, ce qui est assez élevé. Les deux modèles les plus performants sont le modèle de base GLM et le modèle de boosting de gradient stochastique. La suite de l'analyse sera donc spécifique à ces deux modèles.


\newpage

# Interprétation des meilleurs modèles

Dans cette section, on interprète le modèle de base, soit le modèle linéaire généralisé, et le modèle de gradient stochastique car ce sont ceux ayant la meilleure performance sous la mesure _AUC_ de la qualité de l'ajustement. Les méthodes utilisées pour l'interprétation diffèreront entres-autres car le modèle de boosting de gradient stochastique est construit sur un nombre élevé d'arbres. Pour avoir l'effet spécifique de chacune des variables sur la prévision, il faudrait analyser chacun des arbres individuellement, ce qui n'est évidemment pas optimal. On aura recourt à des outils permettant de visualiser l'impact global de chacune des variables sur l'ensemble des arbres, ce qui est un peu moins précis que pour le modèle de base. Le GLM permet d'avoir un facteur associé à chacune des variables directement. Ces facteurs sont une mesure directe de l'impact des variables sur la prévision. Ainsi, on tente d'avoir une mesure semblable pour le modèle de boosting de gradient nous permettant de visualiser l'impact des variables sur la prévision sans avoir à passer en revu chacun des arbres entrainés.

## Modèle de base

Comme mentionné précédemment, l'interprétation de ce modèle ce fera sur les valeurs que prend les coefficients, soit les valeurs des $\beta_i$ qui multiplie chacune des variables dans l'équation. Étant donné qu'on modelise la probabilité de non-renouvellement des assurés de cette compagnie d'assurance, le lien logistique a été utilisé dans l'élaboration du modèle. En isolant, on peut obtenir l'équation suivante : 

$\eta = ln\left(\frac{\pi_{res}}{1 - \pi_{res}}\right) \quad \Leftrightarrow \quad \pi_{res} = \frac{e^{\eta}}{1 + e^{\eta}}$ (fn expit)

L'interprétation qui en ressort est que lorsque la fonction est croissante lorsque $\eta$ augmente et décroissante lorsque que $\eta$ est décroissant. Il est à noter que $\eta$ représente la probabilité de résignation de l'assuré pour lequel on veut obtenir une prévision. Sachant que l'équation du modèle est la suivante :

$\eta = \sum\limits_{j=1}^p \beta_{j} x_{j}$

Un coefficient négatif indique que la probabilité de résignation de la police d'assurance diminue et inversement, lorsque le coefficient est positif, la probabilité de résignation augmente. Sachant que le modèle comprend un grand nombre de variables explicatives, un tableau résumé (voir \autoref{tbl:glm_coeff}) a été conçu et ajouté à ce rapport dans le but de synthétiser l'interprétation qu'on peut en faire. Le coefficient d'origine aura un impact négatif sur la prévision. C'est-à-dire que la prévision part avec une probabilité de résignation qui diminue. De plus, selon l'équation du modèle plus la valeur d'une variable est élevée plus l'impact sur la prévision sera marquable sur la prévision. 

On interprète ensuite le tableau comme suit :

- Les variables *polholder_age*, *policy_age*, *prem_last*, *prem_market* et *vehicl_age* feront baisser la probabilité de résignation. Ainsi, plus l'âge de l'assuré, l'âge du véhicule et l'âge de la police augmente et plus la probabilité de non-renouvellement diminue. De plus, plus la prime du marché augmente plus les assurés seront tenté de garder leur police d'assurance car ils n'auront pas intérêt à s'assurer ailleurs à un prix qui vient tout juste d'augmenter ;

- *prem_final* : l'augmentation de la prime proposée pour le renouvellement de la police fait augmenter la probabilité de résignation, ce qui fait beaucoup de sens ;

- *polholder_diffdriver* : Une police ayant un conducteur de 24 ans et plus n'aura aucun impact sur la probabilité. La probabilité de résignation sera par contre plus élevée si le conducteur est un apprenti, un partenaire ou un jeune, tandis que la probabilité sera plus faible lorsque le conducteur est un utilisateur commerciale ou un utilisateur seul ;

- *Polholder_age* : Le sexe de l'assuré n'aura aucun impact sur la probabilité lorsque l'assuré est un femme tandis que lorsque l'assuré est un homme, la probabilité de résignation aura tendance à augmenter ;

- *polholder_BMCevol* : La probabilité de résignation reste neutre lorsque la prime a baissée depuis le dernier renouvellement. L'impact sur la prévision sera cependant négatif lorsque la prime a augmentée ou est restée stable depuis le dernier renouvellement ;

- *polholder_job* : L'emploi de l'assuré n'aura aucun impact sur la prévision si l'assuré travaille dans le domaine médical. Dans tout autre domaine, le prévision aura tendance augmenter et donc l'assuré sera plus prompt à résigner sa police d'assurance.

- *vehicl_region* : Ne sachant pas le nom des régions des assurés, il est impossible de ressortir une cause possible, mais la région de l'assuré n'aurau aucun effet sur la prévision lorsqu'elle est de 1. L'effet sera négatif pour les régions 2, 5 et 7 et positif pour toutes les autres régions ;

- *prem_freqperyear* : pour ce qui est de cette variables, une fréquence de paiement choisie à une fois par année n'aura aucun impact sur la probabilité de résigner. Les assurés faisant des paiements semestrielles auront une probabilité moins élevée de résigner leur police et comparativement à ceux faisant leur paiement semestriellement ou mensuellement qui auront une probabilité plus élevée.

```{r load_glm_base}
glm_base <- readRDS("../src/01-glm/mod_glm_final.rds")
```

```{r, glm_coeff_table, results='asis'}
coeff_names <- c("Intercept", "polholder age", "polholder BMCevol (inchangée, hausse)", "polholder diffdriver (apprenti, partenaire, jeune)", "polholder diffdriver (commerciale, utilisateur seul)", "polholder gender (Male)", "polholder job (normal)", "policy age", "prem final", "prem freqyear (2)", "prem freqyear (4, 12)", "prem last", "prem market", "vehicl age", "vehicl region (3, 4, 6, 8 à 14)", "vehicl region (2, 5, 7)")
coeff_positif <- c("", "", "", "x", "", "x", "x", "", "x", "", "x", "", "", "", "x", "")
coeff_negatif <- c("x", "x", "x", "", "x", "", "", "x", "", "x", "", "x", "x", "x", "", "x")
niv_inclu <- c("-", "-", "baisse", "24 ans et plus", "24 ans et plus", "Female", "medical", "-", "-", "1", "1", "-", "-", "-", "1", "1")
lasso.names0 <- data.frame(Coefficients = coeff_names, Positif = coeff_positif,
                           Negatif = coeff_negatif, "Niveau neutre" = niv_inclu)
Rmd_table(lasso.names0, label="tbl:glm_coeff", 
          caption="Signe des coefficients du GLM", align = c("l", "l","c", "c", "r"))
```

Étant donné le grand nombre de variables ayant un impact sur la prévision, on a cru bon d'intégrer à l'interprétation un tableau sommatif des variables ayant le plus grand impact sur la prévision (voir \autoref{tbl:betas}). De ce tableau, on peut voir que ces variables sont *polholder_BMCevol*, *polholder_diffdriver* et *vehicl_region*. Plus particulièrement, on parle des polices ayant connu une hausse dans le montant de la prime depuis le dernier renouvellement, les conducteurs utilisant leur véhicule pour une raison commerciale et les polices ayant de jeunes conducteur inscrits, les assurés effectuant leur paiement semestriellement et les assurés vivant dans les régions 2, 12, 13 et 14. Les polices ayant des caractéristiques faisant partie de celles nommées précédemment et figurant dans la \autoref{tbl:betas} sont donc ceux ayant une probabilité de résignation plus succeptible de varier et qui sera plus instable selon ce modèle.

```{r, glm_valeurs_des_betas, results='asis'}
coefficients.glm <- summary(glm_base)$coefficients[,1][which(abs(summary(glm_base)$coefficients[,1]) > 0.35)]
coefficients <- round(as.data.frame(coefficients.glm)$coefficients.glm, 4)
variables <- c("Intercept", "polholder BMCevol (stable)", "polholder BMCevol (hausse)", "polholder diffdriver (commerciale)", "polholder diffdriver (apprenti)", "polholder diffdriver(jeune)", "prem freqperyear(2)", "vehicl region (2)", "vehicl region (12)", "vehicl region (13)", "vehicl region (14)")
betas <- cbind(variables, coefficients)
Rmd_table(betas, label="tbl:betas", 
          caption="Valeurs des coefficients ayant le plus grand impact sur la prévision.",
          align = c("l", "l", "r"))
```

\newpage

## Boosting de gradient stochastique

```{r, load.statHFriedman}
load(file = "../src/07-gbm/int_prem_index.rds")
load(file = "../src/07-gbm/int_vehicl_region.rds")
load(file="../src/07-gbm/gbm_Bern_final.rds")
load(file="../src/07-gbm/gbm_opti_ROC.rds")
load(file = "../src/07-gbm/pdp_prem_index.rds")
load(file = "../src/07-gbm/pdp_vehicl_region.rds")
load(file = "../src/07-gbm/pdp_policy_age.rds")
```

L'interprétation de ce modèle, étant plus demandante que pour le modèle de base étant donné le nombre élevé d'arbre entrainé, certains outil devront être utilisés. Ces outils sont l'importance des variables, les graphiques de dépendance partielle et la statistique H de Friedman.

L'importance des variables nous permet de comprendre l'influence des variables explicatives sur la prévision. Ainsi, on peut visualiser les variables du modèles ayant le plus grand impact sur la prévision. De la \autoref{fig:imp-gbm}, on voit que les variables les plus significatives sur ce modèles sont définitivement *prem_index* et *vehicl_region*, tout comme *prem_freqperyear*, *polholder_age* et *vehicl_age* et d'autres mais qui ont une mesure d'importance moins considérable que les deux premières. Les valeurs sur laquelles ont ce fient pour tirer cette conclusion vient de l'importance relative des variables prises individuellement sur la prévision. Plus cette valeur est élevée, plus la valeur de la variable a un impact non-négligeable sur la prévision. Dans le but de mieux comprendre l'effet individuel des variables ayant le plus grand impact, on utilisera l'outil des graphiques de dépendances partielles en se concentrant sur les variables *prem_index* et *vehicl_region*. 

<!--\input{tbl_iml_gbm.tex}-->
<!--[Graphique de l'importance des variables sur la prévision](../src/07-gbm/imp_gbm.png)-->
\begin{figure}
\centering
\includegraphics{../src/07-gbm/imp_gbm}
\caption{Graphique de l'importance des variables sur la prévision}
\label{fig:imp-gbm}
\end{figure}

Ces graphiques permettent une interprétation plus spécifique. Étant donné que l'importance des variables ne nous permet pas de comprendre l'effet isolée d'une variable explicative sur la prévision, c'est à l'aide de cette outil qu'on pourra en faire l'interprétation. Il est ainsi utilisé pour mieux comprendre l'effet global d'une variable explicative sur la prévision et peut être interprété comme la moyenne des ICEs, soit l'espérance conditionnelle individuelle pour chacune des observations. 

Le graphique de gauche de la \autoref{tbl:pdppartie1} nous permet de voir que pour une valeur de *prem_index* ce situant entre 0 et 0.6, la probabilité de résignation est beaucoup plus faible. Ainsi, un assuré peut avoir un pourcentage d'augmentation de sa prime au renouvellement allant jusqu'à presque 50% sans qu'il y ait nécessairement un impact sur sa probabilité de résigner. C'est lorsque l'augmentation dépasse les 55% environ qu'on remarque l'impact de l'augmentation de la prime sur la probabilité de résigner.

Le graphique de droite de la \autoref{tbl:pdppartie1} nous permet, quant-à-elle, de voir que les régions 11 à 14 sont celle affectant le plus la probabilité de ne pas renouveller la police d'assurance. L'impact le plus marqué est observé auprès des assurés ayant comme région de résidence la région 12 et l'impact le moins marqué est observé auprès des résidents de la région 2. Étant donné que les noms des régions n'ont pas été divulgués par la compagnie d'ou provient le jeu de données, il est impossible pour nous de faire un lien entre la région et l'impact que celle-ci peut avoir sur la décision de l'assuré qui y habite.

\begin{figure}
\centering
\begin{minipage}{0.48\linewidth}
```{r pdp_prem_index, results='asis'}
plot(gbm_opti_Bern, 19, gbmfit_Bern$bestTune["n.trees"], type ="response")
```
\end{minipage}
\hfill
\begin{minipage}{0.48\linewidth}
```{r pdp_vehicl_region, results='asis'}
plot(gbm_opti_Bern, 18, gbmfit_Bern$bestTune["n.trees"], type ="response")
```
\end{minipage}
\caption{Graphique de dépendance partielle pour les variables prem.index et vehicl.region.}
\label{tbl:pdppartie1}
\end{figure}


\begin{figure}
\centering
\begin{minipage}{0.48\linewidth}
```{r pdp_prem_policy_age, results='asis'}
plot(gbm_opti_Bern, 6, gbmfit_Bern$bestTune["n.trees"], type ="response")
```
\end{minipage}
\hfill
\begin{minipage}{0.48\linewidth}
```{r pdp_prem_freqperyear, results='asis'}
plot(gbm_opti_Bern, 10, gbmfit_Bern$bestTune["n.trees"], type ="response")
```
\end{minipage}
\caption{Graphique de dépendance partielle pour les variables policy.age et prem.freqperyear.}
\label{tbl:pdppartie2}
\end{figure}

De plus, en jettant un coup d'oeil aux autres variables ayant un importance marquée sur la prévision, il a été possible d'observer un effet important de l'âge de la police et de la fréquance de paiement de la prime sur la probabilité de résignation d'où l'ajout de la \autoref{tbl:pdppartie2} à ce rapport. Dans celles-ci, on peut observer que la probabilité de résignation diminue avec l'âge de la police, ce qui était attendu. De plus dès que la police atteint plus de 5 ans, cette probabilité reste stable a une valeur qui s'approche grandement de la valeur nulle. Dans le cas de la variable *prem_freqperyear*, on observe que plus la fréquence de paiement est élevé, plus la probabilité de résignation diminue.

\newpage

Pour ce qui est de la statistique H de Friedman, elle  est utilisée pour pouvoir estimer la force des interractions entre une variable précisement et tous les autres variables en mesurant la quantité de la variance qui provient de cet interraction dans la prévision. On peut ainsi observer les variables qui interragissent avec les variables les plus importantes pour expliquer la prévision, soit les variables *prem_index* et *vehicl_region*. Sachant que la profondeur maximale de l'arbre pour ce modèle est de `r gbmfit_Bern$bestTune["interaction.depth"]`, il pourrait y avoir des interraction sur jusqu'à `r gbmfit_Bern$bestTune["interaction.depth"]` variables différentes. Par cet statistique, on obtient les graphiques suivants.

```{r int_prem_index, results='asis', fig.height=3, fig.cap="\\label{int}Graphique de l'importance des interractions entre la variables prem.index et les autres variables sur la prévision"}
plot(int.prem_index)
```

La \autoref{int} est un exemple de graphique obtenu en utilisant cette statistique. On peut ensuite utiliser les graphiques de dépendance partielle pour voir l'impact des interractions ayant la plus grande force sur la prévision. Après analyse, seul l'interraction *vehicl_region:prem_index* donne une interprétation intéressante. À partir de graphique de dépendance partielle de la \autoref{pdp}, on peut observer que certaines régions possède un creux où la probabilité de résignation est beaucoup plus faible lorsque le pourcentage d'augmentation de la prime ce situe entre 0 et 50% dont les régions 1, 2, 8, 9, 12, 13 et 14. Pour ce qui est des autres régions, la probabilité de résignation demeure assez stable et faible lorsque le pourcentage d'augmentation est supérieur à 0%. Un dernier constat intéressant concerne d'ailleurs la région 6 et 7, où la probabilité de résignation est plus faible si la prime augmente que si elle diminue, ce qui est contre-intuitif.

```{r dpd_interraction, results='asis', fig.heigth=3, fig.cap="\\label{pdp}Graphique de dépendance partielle pour l'interraction entre la variable vehicl.region et la variable prem.index"}
plot(gbm_opti_Bern, 18:19, gbmfit_Bern$bestTune["n.trees"], type="response")
```



\newpage

# Conclusion

\newpage

# Bibliographie
